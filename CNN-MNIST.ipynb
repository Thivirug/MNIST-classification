{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of Convolutional Neural Networks (CNNs) for Image Classification\n",
    "\n",
    "Convolutional Neural Networks (CNNs) are a class of deep learning models specifically designed for processing structured grid data, such as images. They are particularly effective for image classification tasks due to their ability to automatically and adaptively learn spatial hierarchies of features from input images.\n",
    "\n",
    "#### Problem Representation\n",
    "In the context of image classification, the problem involves categorizing images into predefined classes. For example, in the MNIST dataset, the task is to classify 28x28 pixel grayscale images of handwritten digits (0-9) into one of the 10 digit classes.\n",
    "\n",
    "#### Main Steps in CNN Algorithm Implementation\n",
    "\n",
    "1. **Data Loading and Transformation**:\n",
    "   - Load the MNIST dataset.\n",
    "   - Apply transformations to the images, such as resizing and normalization.\n",
    "\n",
    "2. **Define the CNN Model**:\n",
    "   - Create a CNN model with convolutional layers, activation functions, pooling layers, and fully connected layers.\n",
    "\n",
    "3. **Training the Model**:\n",
    "   - Train the CNN model using the training dataset.\n",
    "   - Optimize the model parameters using backpropagation and an optimization algorithm (e.g., Adam).\n",
    "\n",
    "4. **Testing the Model**:\n",
    "   - Evaluate the trained model on the test dataset to measure its performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn #To build the Neural Network\n",
    "import heading #To get useful functions\n",
    "from torchvision import datasets #To load the dataset\n",
    "import matplotlib.pyplot as plt #To plot results\n",
    "from torch.utils.data import DataLoader #To load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_img(img_dimension):\n",
    "    \"\"\"Returns a transformation for images including resizing.\n",
    "\n",
    "    Args:\n",
    "        img_dimension (int): The dimension of the image.\n",
    "\n",
    "    Returns:\n",
    "        torchvision.transforms: The transformation for the image.\n",
    "    \"\"\"\n",
    "    return heading.resize_image(img_dimension) #transform the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_MNIST_data(train_bool, transform_img, batch_size=1):\n",
    "    \"\"\"Loads the MNIST dataset.\n",
    "\n",
    "    Args:\n",
    "        train_bool (boolean): True if training, False if testing.\n",
    "        img_transform (torchvision.transforms): The transformation for the image.\n",
    "        batch_size (int): Number of samples per batch. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        torch.DataLoader: The data loader for the MNIST dataset.\n",
    "    \"\"\"\n",
    "    #Load the dataset\n",
    "    load_dataset = datasets.MNIST(root='./Data', train=train_bool, download=True, transform=transform_img)\n",
    "\n",
    "    return DataLoader(dataset=load_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Side Note:\n",
    "* Image tensors are represented as a tuple in the format, (batch_size, height, width, channels). The batch size is the number of images in a batch, the height and width are the dimensions of the image, and the channels are the color channels of the image. For example, a batch of 32 images with a height of 28 pixels, a width of 28 pixels, and 1 color channel would be represented as (32, 28, 28, 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell below, defines a class that implements a Convolutional Neural Network for Image Classification using pytorch. Its layer details are as follows,\n",
    "\n",
    "### Convolutional Layer 1: \n",
    "* 1 input channel (Gray scale)\n",
    "* 64 output channels - Meaning 64 different filters are applied to the input image\n",
    "* 2x2 kernel size\n",
    "* stride 1\n",
    "* padding 1\n",
    "* Activation Function: ReLU\n",
    "* Pooling Layer: Max Pooling with 2x2 kernel size\n",
    "* Batch Normalisation: Applied to 64 features\n",
    "\n",
    "### Convolutional Layer 2:\n",
    "* 64 input channels\n",
    "* 128 output channels - Meaning 128 different filters are applied to the input image\n",
    "* 2x2 kernel size\n",
    "* stride 1\n",
    "* padding 1\n",
    "* Activation Function: ReLU\n",
    "* Pooling Layer: Max Pooling with 2x2 kernel size\n",
    "* Batch Normalisation: Applied to 128 features\n",
    "\n",
    "### Flattening Layer:\n",
    "* Afrer conv 2 layer, the output has 128 channels, and spatial dimesnions 7x7. \n",
    "* Therefore, it is flattened to a 2D tensor of size (batch_size, 128x7x7)\n",
    "\n",
    "### Fully Connected Layer 1:\n",
    "* 7x7x128 input features\n",
    "* 512 output features\n",
    "* Dropout ratio of 0.1\n",
    "* Activation Function: ReLU\n",
    "\n",
    "### Fully Connected Layer 2:\n",
    "* 512 input features\n",
    "* 128 output features\n",
    "* Dropout ratio of 0.5\n",
    "* Activation Function: ReLU\n",
    "\n",
    "### Fully Connected Layer 3:\n",
    "* 128 input features\n",
    "* 10 output features\n",
    "\n",
    "### Output Layer:\n",
    "* 10 output features corresponding to the 10 classes (10 numbers) of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONV_IMG(nn.Module):\n",
    "    def __init__(self, num_input_channels=1, num_output_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        #Convolutional Layer 1\n",
    "        self.conv1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(num_input_channels, out_channels=64, kernel_size=2, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2),\n",
    "            torch.nn.BatchNorm2d(num_features=64)  #atch normalization for 64 features\n",
    "        )\n",
    "        #conv1 - Input size = 28x28x1, Output size = 28x28x64, After pooling = 14x14x64\n",
    "\n",
    "        #Convolutional Layer 2\n",
    "        self.conv2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=2, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2),\n",
    "            torch.nn.BatchNorm2d(num_features=128)  # Batch normalization for 128 features\n",
    "        )\n",
    "        #conv2 - Input size = 14x14x64, Output size = 14x14x128, After pooling = 7x7x128\n",
    "\n",
    "        #Fully Connected Layer 1\n",
    "        self.fc1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=7*7*128, out_features=512),\n",
    "            torch.nn.Dropout(0.1),  #Dropout for regularization\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "\n",
    "        #Fully Connected Layer 2\n",
    "        self.fc2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=512, out_features=128),\n",
    "            torch.nn.Dropout(0.1),  #Dropout for regularization\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "\n",
    "        #Fully Connected Layer 3\n",
    "        self.fc3 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=128, out_features=num_output_classes)\n",
    "            #softmax is not needed here because CrossEntropyLoss applies softmax\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Performs a forward pass through the neural network.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor after passing through the network.\n",
    "        \"\"\"\n",
    "        #forward pass through convolutional layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        #Flatten the final output from the conv layers\n",
    "        #x.size(0) is the batch size and specifies the size of the first dimension of the reshaped tensor\n",
    "        #The second argument -1 is a placeholder that allows PyTorch to automatically infer\n",
    "        #the size of the second dimension based on the original size of the tensor and the specified size of the first dimension\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        #Forward pass through fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How the CNN Model Works to solve the problem:\n",
    "\n",
    "1) **Input Tensor:** The function forward takes an input tensor x, which represents the data I want to pass through the network. This tensor typically contains image data.\n",
    "\n",
    "2) **Convolutional Layers:**\n",
    "\n",
    "* x = self.conv1(x): The input tensor x is passed through the first convolutional layer (conv1). This layer applies a set of filters to the input image, performing convolution operations to extract local features such as edges, textures, etc.\n",
    "* x = self.conv2(x): The output from the first convolutional layer is then passed through the second convolutional layer (conv2). This layer further processes the features extracted by the first layer, capturing more complex patterns and structures.\n",
    "\n",
    "3) **Flattening:**\n",
    "\n",
    "* x = x.view(x.size(0), -1): After the convolutional layers, the tensor is flattened. Flattening transforms the multi-dimensional tensor into a 2D tensor where the first dimension is the batch size, and the second dimension is the flattened feature vector. This step is necessary to prepare the data for the fully connected layers.\n",
    "\n",
    "4) **Fully Connected Layers:**\n",
    "\n",
    "* x = self.fc1(x): The flattened tensor is passed through the first fully connected layer (fc1). This layer combines the features extracted by the convolutional layers to form higher-level representations.\n",
    "* x = self.fc2(x): The output from the first fully connected layer is then passed through the second fully connected layer (fc2). This layer further refines the representations.\n",
    "* x = self.fc3(x): Finally, the output from the second fully connected layer is passed through the third fully connected layer (fc3). This layer produces the final output of the network, which are logits representing the predicted class scores.\n",
    "\n",
    "5) **Output Tensor:** The final output tensor x is returned. This tensor represents the network's predictions based on the input data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn(num_input_channels, num_output_classes, training_dataloader, num_epochs, learning_rate):\n",
    "    \"\"\"Trains a Convolutional Neural Network (CNN) model.\n",
    "\n",
    "    Args:\n",
    "        num_input_channels (int): Number of input channels.\n",
    "        num_output_classes (int): Number of output classes.\n",
    "        training_dataloader (DataLoader): DataLoader for training data.\n",
    "        num_epochs (int): Number of training epochs.\n",
    "        learning_rate (float): Learning rate for the optimizer.\n",
    "        \n",
    "    Returns:\n",
    "        CONV_Img : Trained CNN model.\n",
    "    \"\"\"\n",
    "\n",
    "    #create an instance of the CNN\n",
    "    cnn = CONV_IMG(num_input_channels=num_input_channels, num_output_classes=num_output_classes)\n",
    "\n",
    "    #create the neural network\n",
    "    network = heading.create_network(cnn)\n",
    "\n",
    "    #train model using heading.trian_model()\n",
    "    trained_model = heading.train_model(net=network, train_loader=training_dataloader, epochs=num_epochs, LR=learning_rate)\n",
    "\n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cnn(trained_model, test_dataloader):\n",
    "    \"\"\"Tests a Convolutional Neural Network (CNN) model. Returns accuracy.\n",
    "\n",
    "    Args:\n",
    "        trained_model (CONV_IMG): Trained CNN model.\n",
    "        test_dataloader (DataLoader): DataLoader for testing data.\n",
    "\n",
    "    Returns:\n",
    "        float: Accuracy of the model\n",
    "    \"\"\"\n",
    "    return heading.test_cnn(trained_model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,100] loss:0.884\n",
      "[1,200] loss:0.450\n",
      "[1,300] loss:0.417\n",
      "[1,400] loss:0.285\n",
      "[1,500] loss:0.276\n",
      "[1,600] loss:0.276\n",
      "[1,700] loss:0.242\n",
      "[1,800] loss:0.189\n",
      "[1,900] loss:0.214\n",
      "[1,1000] loss:0.193\n",
      "[1,1100] loss:0.244\n",
      "[1,1200] loss:0.198\n",
      "[1,1300] loss:0.170\n",
      "[1,1400] loss:0.202\n",
      "[1,1500] loss:0.211\n",
      "[1,1600] loss:0.212\n",
      "[1,1700] loss:0.172\n",
      "[1,1800] loss:0.207\n",
      "[1,1900] loss:0.167\n",
      "[1,2000] loss:0.152\n",
      "[1,2100] loss:0.160\n",
      "[1,2200] loss:0.153\n",
      "[1,2300] loss:0.179\n",
      "[1,2400] loss:0.152\n",
      "[1,2500] loss:0.122\n",
      "[1,2600] loss:0.168\n",
      "[1,2700] loss:0.133\n",
      "[1,2800] loss:0.126\n",
      "[1,2900] loss:0.152\n",
      "[1,3000] loss:0.151\n",
      "[1,3100] loss:0.116\n",
      "[1,3200] loss:0.141\n",
      "[1,3300] loss:0.135\n",
      "[1,3400] loss:0.159\n",
      "[1,3500] loss:0.158\n",
      "[1,3600] loss:0.164\n",
      "[1,3700] loss:0.164\n",
      "[2,100] loss:0.136\n",
      "[2,200] loss:0.099\n",
      "[2,300] loss:0.134\n",
      "[2,400] loss:0.126\n",
      "[2,500] loss:0.116\n",
      "[2,600] loss:0.157\n",
      "[2,700] loss:0.128\n",
      "[2,800] loss:0.116\n",
      "[2,900] loss:0.109\n",
      "[2,1000] loss:0.134\n",
      "[2,1100] loss:0.116\n",
      "[2,1200] loss:0.141\n",
      "[2,1300] loss:0.105\n",
      "[2,1400] loss:0.127\n",
      "[2,1500] loss:0.104\n",
      "[2,1600] loss:0.147\n",
      "[2,1700] loss:0.127\n",
      "[2,1800] loss:0.096\n",
      "[2,1900] loss:0.145\n",
      "[2,2000] loss:0.111\n",
      "[2,2100] loss:0.114\n",
      "[2,2200] loss:0.140\n",
      "[2,2300] loss:0.103\n",
      "[2,2400] loss:0.127\n",
      "[2,2500] loss:0.141\n",
      "[2,2600] loss:0.129\n",
      "[2,2700] loss:0.137\n",
      "[2,2800] loss:0.095\n",
      "[2,2900] loss:0.125\n",
      "[2,3000] loss:0.080\n",
      "[2,3100] loss:0.132\n",
      "[2,3200] loss:0.118\n",
      "[2,3300] loss:0.107\n",
      "[2,3400] loss:0.122\n",
      "[2,3500] loss:0.113\n",
      "[2,3600] loss:0.113\n",
      "[2,3700] loss:0.109\n",
      "[3,100] loss:0.086\n",
      "[3,200] loss:0.082\n",
      "[3,300] loss:0.089\n",
      "[3,400] loss:0.110\n",
      "[3,500] loss:0.095\n",
      "[3,600] loss:0.075\n",
      "[3,700] loss:0.118\n",
      "[3,800] loss:0.108\n",
      "[3,900] loss:0.097\n",
      "[3,1000] loss:0.079\n",
      "[3,1100] loss:0.108\n",
      "[3,1200] loss:0.102\n",
      "[3,1300] loss:0.100\n",
      "[3,1400] loss:0.116\n",
      "[3,1500] loss:0.083\n",
      "[3,1600] loss:0.123\n",
      "[3,1700] loss:0.099\n",
      "[3,1800] loss:0.083\n",
      "[3,1900] loss:0.107\n",
      "[3,2000] loss:0.077\n",
      "[3,2100] loss:0.071\n",
      "[3,2200] loss:0.100\n",
      "[3,2300] loss:0.126\n",
      "[3,2400] loss:0.114\n",
      "[3,2500] loss:0.120\n",
      "[3,2600] loss:0.081\n",
      "[3,2700] loss:0.072\n",
      "[3,2800] loss:0.072\n",
      "[3,2900] loss:0.102\n",
      "[3,3000] loss:0.071\n",
      "[3,3100] loss:0.117\n",
      "[3,3200] loss:0.094\n",
      "[3,3300] loss:0.098\n",
      "[3,3400] loss:0.106\n",
      "[3,3500] loss:0.130\n",
      "[3,3600] loss:0.103\n",
      "[3,3700] loss:0.090\n",
      "[4,100] loss:0.070\n",
      "[4,200] loss:0.118\n",
      "[4,300] loss:0.088\n",
      "[4,400] loss:0.077\n",
      "[4,500] loss:0.082\n",
      "[4,600] loss:0.089\n",
      "[4,700] loss:0.083\n",
      "[4,800] loss:0.083\n",
      "[4,900] loss:0.084\n",
      "[4,1000] loss:0.100\n",
      "[4,1100] loss:0.065\n",
      "[4,1200] loss:0.094\n",
      "[4,1300] loss:0.091\n",
      "[4,1400] loss:0.100\n",
      "[4,1500] loss:0.085\n",
      "[4,1600] loss:0.093\n",
      "[4,1700] loss:0.107\n",
      "[4,1800] loss:0.092\n",
      "[4,1900] loss:0.083\n",
      "[4,2000] loss:0.076\n",
      "[4,2100] loss:0.063\n",
      "[4,2200] loss:0.081\n",
      "[4,2300] loss:0.080\n",
      "[4,2400] loss:0.105\n",
      "[4,2500] loss:0.090\n",
      "[4,2600] loss:0.075\n",
      "[4,2700] loss:0.092\n",
      "[4,2800] loss:0.111\n",
      "[4,2900] loss:0.104\n",
      "[4,3000] loss:0.074\n",
      "[4,3100] loss:0.080\n",
      "[4,3200] loss:0.069\n",
      "[4,3300] loss:0.087\n",
      "[4,3400] loss:0.106\n",
      "[4,3500] loss:0.118\n",
      "[4,3600] loss:0.080\n",
      "[4,3700] loss:0.056\n",
      "[5,100] loss:0.085\n",
      "[5,200] loss:0.069\n",
      "[5,300] loss:0.053\n",
      "[5,400] loss:0.059\n",
      "[5,500] loss:0.083\n",
      "[5,600] loss:0.085\n",
      "[5,700] loss:0.051\n",
      "[5,800] loss:0.065\n",
      "[5,900] loss:0.104\n",
      "[5,1000] loss:0.093\n",
      "[5,1100] loss:0.068\n",
      "[5,1200] loss:0.126\n",
      "[5,1300] loss:0.096\n",
      "[5,1400] loss:0.061\n",
      "[5,1500] loss:0.112\n",
      "[5,1600] loss:0.068\n",
      "[5,1700] loss:0.067\n",
      "[5,1800] loss:0.080\n",
      "[5,1900] loss:0.059\n",
      "[5,2000] loss:0.072\n",
      "[5,2100] loss:0.085\n",
      "[5,2200] loss:0.067\n",
      "[5,2300] loss:0.071\n",
      "[5,2400] loss:0.084\n",
      "[5,2500] loss:0.060\n",
      "[5,2600] loss:0.098\n",
      "[5,2700] loss:0.081\n",
      "[5,2800] loss:0.072\n",
      "[5,2900] loss:0.077\n",
      "[5,3000] loss:0.076\n",
      "[5,3100] loss:0.116\n",
      "[5,3200] loss:0.054\n",
      "[5,3300] loss:0.091\n",
      "[5,3400] loss:0.074\n",
      "[5,3500] loss:0.071\n",
      "[5,3600] loss:0.080\n",
      "[5,3700] loss:0.064\n",
      "[6,100] loss:0.068\n",
      "[6,200] loss:0.067\n",
      "[6,300] loss:0.092\n",
      "[6,400] loss:0.063\n",
      "[6,500] loss:0.072\n",
      "[6,600] loss:0.088\n",
      "[6,700] loss:0.089\n",
      "[6,800] loss:0.072\n",
      "[6,900] loss:0.075\n",
      "[6,1000] loss:0.061\n",
      "[6,1100] loss:0.085\n",
      "[6,1200] loss:0.067\n",
      "[6,1300] loss:0.083\n",
      "[6,1400] loss:0.064\n",
      "[6,1500] loss:0.063\n",
      "[6,1600] loss:0.072\n",
      "[6,1700] loss:0.072\n",
      "[6,1800] loss:0.086\n",
      "[6,1900] loss:0.051\n",
      "[6,2000] loss:0.086\n",
      "[6,2100] loss:0.070\n",
      "[6,2200] loss:0.083\n",
      "[6,2300] loss:0.080\n",
      "[6,2400] loss:0.070\n",
      "[6,2500] loss:0.064\n",
      "[6,2600] loss:0.064\n",
      "[6,2700] loss:0.078\n",
      "[6,2800] loss:0.086\n",
      "[6,2900] loss:0.055\n",
      "[6,3000] loss:0.040\n",
      "[6,3100] loss:0.068\n",
      "[6,3200] loss:0.104\n",
      "[6,3300] loss:0.086\n",
      "[6,3400] loss:0.075\n",
      "[6,3500] loss:0.050\n",
      "[6,3600] loss:0.059\n",
      "[6,3700] loss:0.077\n",
      "[7,100] loss:0.065\n",
      "[7,200] loss:0.057\n",
      "[7,300] loss:0.062\n",
      "[7,400] loss:0.042\n",
      "[7,500] loss:0.048\n",
      "[7,600] loss:0.097\n",
      "[7,700] loss:0.054\n",
      "[7,800] loss:0.082\n",
      "[7,900] loss:0.067\n",
      "[7,1000] loss:0.067\n",
      "[7,1100] loss:0.053\n",
      "[7,1200] loss:0.047\n",
      "[7,1300] loss:0.070\n",
      "[7,1400] loss:0.047\n",
      "[7,1500] loss:0.089\n",
      "[7,1600] loss:0.066\n",
      "[7,1700] loss:0.069\n",
      "[7,1800] loss:0.081\n",
      "[7,1900] loss:0.054\n",
      "[7,2000] loss:0.078\n",
      "[7,2100] loss:0.081\n",
      "[7,2200] loss:0.079\n",
      "[7,2300] loss:0.078\n",
      "[7,2400] loss:0.071\n",
      "[7,2500] loss:0.056\n",
      "[7,2600] loss:0.087\n",
      "[7,2700] loss:0.072\n",
      "[7,2800] loss:0.051\n",
      "[7,2900] loss:0.057\n",
      "[7,3000] loss:0.087\n",
      "[7,3100] loss:0.042\n",
      "[7,3200] loss:0.071\n",
      "[7,3300] loss:0.078\n",
      "[7,3400] loss:0.054\n",
      "[7,3500] loss:0.062\n",
      "[7,3600] loss:0.068\n",
      "[7,3700] loss:0.054\n",
      "[8,100] loss:0.069\n",
      "[8,200] loss:0.046\n",
      "[8,300] loss:0.038\n",
      "[8,400] loss:0.058\n",
      "[8,500] loss:0.076\n",
      "[8,600] loss:0.047\n",
      "[8,700] loss:0.101\n",
      "[8,800] loss:0.063\n",
      "[8,900] loss:0.084\n",
      "[8,1000] loss:0.081\n",
      "[8,1100] loss:0.060\n",
      "[8,1200] loss:0.076\n",
      "[8,1300] loss:0.055\n",
      "[8,1400] loss:0.045\n",
      "[8,1500] loss:0.043\n",
      "[8,1600] loss:0.046\n",
      "[8,1700] loss:0.060\n",
      "[8,1800] loss:0.075\n",
      "[8,1900] loss:0.065\n",
      "[8,2000] loss:0.073\n",
      "[8,2100] loss:0.073\n",
      "[8,2200] loss:0.053\n",
      "[8,2300] loss:0.077\n",
      "[8,2400] loss:0.047\n",
      "[8,2500] loss:0.054\n",
      "[8,2600] loss:0.072\n",
      "[8,2700] loss:0.079\n",
      "[8,2800] loss:0.092\n",
      "[8,2900] loss:0.083\n",
      "[8,3000] loss:0.064\n",
      "[8,3100] loss:0.045\n",
      "[8,3200] loss:0.066\n",
      "[8,3300] loss:0.057\n",
      "[8,3400] loss:0.059\n",
      "[8,3500] loss:0.042\n",
      "[8,3600] loss:0.077\n",
      "[8,3700] loss:0.043\n",
      "[9,100] loss:0.051\n",
      "[9,200] loss:0.033\n",
      "[9,300] loss:0.066\n",
      "[9,400] loss:0.066\n",
      "[9,500] loss:0.059\n",
      "[9,600] loss:0.055\n",
      "[9,700] loss:0.039\n",
      "[9,800] loss:0.034\n",
      "[9,900] loss:0.056\n",
      "[9,1000] loss:0.079\n",
      "[9,1100] loss:0.060\n",
      "[9,1200] loss:0.071\n",
      "[9,1300] loss:0.049\n",
      "[9,1400] loss:0.057\n",
      "[9,1500] loss:0.065\n",
      "[9,1600] loss:0.066\n",
      "[9,1700] loss:0.073\n",
      "[9,1800] loss:0.083\n",
      "[9,1900] loss:0.070\n",
      "[9,2000] loss:0.071\n",
      "[9,2100] loss:0.034\n",
      "[9,2200] loss:0.026\n",
      "[9,2300] loss:0.096\n",
      "[9,2400] loss:0.067\n",
      "[9,2500] loss:0.070\n",
      "[9,2600] loss:0.059\n",
      "[9,2700] loss:0.053\n",
      "[9,2800] loss:0.066\n",
      "[9,2900] loss:0.075\n",
      "[9,3000] loss:0.061\n",
      "[9,3100] loss:0.063\n",
      "[9,3200] loss:0.057\n",
      "[9,3300] loss:0.051\n",
      "[9,3400] loss:0.047\n",
      "[9,3500] loss:0.058\n",
      "[9,3600] loss:0.056\n",
      "[9,3700] loss:0.069\n",
      "[10,100] loss:0.050\n",
      "[10,200] loss:0.055\n",
      "[10,300] loss:0.079\n",
      "[10,400] loss:0.044\n",
      "[10,500] loss:0.041\n",
      "[10,600] loss:0.060\n",
      "[10,700] loss:0.050\n",
      "[10,800] loss:0.050\n",
      "[10,900] loss:0.048\n",
      "[10,1000] loss:0.049\n",
      "[10,1100] loss:0.066\n",
      "[10,1200] loss:0.075\n",
      "[10,1300] loss:0.050\n",
      "[10,1400] loss:0.049\n",
      "[10,1500] loss:0.058\n",
      "[10,1600] loss:0.088\n",
      "[10,1700] loss:0.060\n",
      "[10,1800] loss:0.056\n",
      "[10,1900] loss:0.076\n",
      "[10,2000] loss:0.056\n",
      "[10,2100] loss:0.062\n",
      "[10,2200] loss:0.059\n",
      "[10,2300] loss:0.061\n",
      "[10,2400] loss:0.053\n",
      "[10,2500] loss:0.046\n",
      "[10,2600] loss:0.038\n",
      "[10,2700] loss:0.047\n",
      "[10,2800] loss:0.044\n",
      "[10,2900] loss:0.045\n",
      "[10,3000] loss:0.047\n",
      "[10,3100] loss:0.049\n",
      "[10,3200] loss:0.036\n",
      "[10,3300] loss:0.066\n",
      "[10,3400] loss:0.037\n",
      "[10,3500] loss:0.046\n",
      "[10,3600] loss:0.067\n",
      "[10,3700] loss:0.051\n",
      "[11,100] loss:0.066\n",
      "[11,200] loss:0.047\n",
      "[11,300] loss:0.035\n",
      "[11,400] loss:0.031\n",
      "[11,500] loss:0.060\n",
      "[11,600] loss:0.052\n",
      "[11,700] loss:0.039\n",
      "[11,800] loss:0.043\n",
      "[11,900] loss:0.036\n",
      "[11,1000] loss:0.076\n",
      "[11,1100] loss:0.065\n",
      "[11,1200] loss:0.034\n",
      "[11,1300] loss:0.056\n",
      "[11,1400] loss:0.066\n",
      "[11,1500] loss:0.053\n",
      "[11,1600] loss:0.064\n",
      "[11,1700] loss:0.031\n",
      "[11,1800] loss:0.036\n",
      "[11,1900] loss:0.083\n",
      "[11,2000] loss:0.047\n",
      "[11,2100] loss:0.056\n",
      "[11,2200] loss:0.075\n",
      "[11,2300] loss:0.052\n",
      "[11,2400] loss:0.038\n",
      "[11,2500] loss:0.045\n",
      "[11,2600] loss:0.037\n",
      "[11,2700] loss:0.051\n",
      "[11,2800] loss:0.044\n",
      "[11,2900] loss:0.040\n",
      "[11,3000] loss:0.057\n",
      "[11,3100] loss:0.054\n",
      "[11,3200] loss:0.071\n",
      "[11,3300] loss:0.054\n",
      "[11,3400] loss:0.050\n",
      "[11,3500] loss:0.056\n",
      "[11,3600] loss:0.055\n",
      "[11,3700] loss:0.048\n",
      "[12,100] loss:0.068\n",
      "[12,200] loss:0.038\n",
      "[12,300] loss:0.041\n",
      "[12,400] loss:0.064\n",
      "[12,500] loss:0.047\n",
      "[12,600] loss:0.051\n",
      "[12,700] loss:0.034\n",
      "[12,800] loss:0.041\n",
      "[12,900] loss:0.042\n",
      "[12,1000] loss:0.039\n",
      "[12,1100] loss:0.022\n",
      "[12,1200] loss:0.051\n",
      "[12,1300] loss:0.049\n",
      "[12,1400] loss:0.040\n",
      "[12,1500] loss:0.045\n",
      "[12,1600] loss:0.053\n",
      "[12,1700] loss:0.050\n",
      "[12,1800] loss:0.058\n",
      "[12,1900] loss:0.058\n",
      "[12,2000] loss:0.051\n",
      "[12,2100] loss:0.067\n",
      "[12,2200] loss:0.069\n",
      "[12,2300] loss:0.042\n",
      "[12,2400] loss:0.044\n",
      "[12,2500] loss:0.051\n",
      "[12,2600] loss:0.055\n",
      "[12,2700] loss:0.046\n",
      "[12,2800] loss:0.063\n",
      "[12,2900] loss:0.049\n",
      "[12,3000] loss:0.036\n",
      "[12,3100] loss:0.054\n",
      "[12,3200] loss:0.054\n",
      "[12,3300] loss:0.035\n",
      "[12,3400] loss:0.046\n",
      "[12,3500] loss:0.050\n",
      "[12,3600] loss:0.046\n",
      "[12,3700] loss:0.054\n",
      "[13,100] loss:0.024\n",
      "[13,200] loss:0.037\n",
      "[13,300] loss:0.050\n",
      "[13,400] loss:0.046\n",
      "[13,500] loss:0.056\n",
      "[13,600] loss:0.052\n",
      "[13,700] loss:0.041\n",
      "[13,800] loss:0.057\n",
      "[13,900] loss:0.028\n",
      "[13,1000] loss:0.047\n",
      "[13,1100] loss:0.050\n",
      "[13,1200] loss:0.043\n",
      "[13,1300] loss:0.043\n",
      "[13,1400] loss:0.036\n",
      "[13,1500] loss:0.062\n",
      "[13,1600] loss:0.035\n",
      "[13,1700] loss:0.050\n",
      "[13,1800] loss:0.049\n",
      "[13,1900] loss:0.041\n",
      "[13,2000] loss:0.041\n",
      "[13,2100] loss:0.049\n",
      "[13,2200] loss:0.038\n",
      "[13,2300] loss:0.036\n",
      "[13,2400] loss:0.070\n",
      "[13,2500] loss:0.042\n",
      "[13,2600] loss:0.042\n",
      "[13,2700] loss:0.059\n",
      "[13,2800] loss:0.045\n",
      "[13,2900] loss:0.073\n",
      "[13,3000] loss:0.058\n",
      "[13,3100] loss:0.029\n",
      "[13,3200] loss:0.060\n",
      "[13,3300] loss:0.054\n",
      "[13,3400] loss:0.023\n",
      "[13,3500] loss:0.078\n",
      "[13,3600] loss:0.048\n",
      "[13,3700] loss:0.050\n",
      "[14,100] loss:0.030\n",
      "[14,200] loss:0.054\n",
      "[14,300] loss:0.041\n",
      "[14,400] loss:0.050\n",
      "[14,500] loss:0.042\n",
      "[14,600] loss:0.049\n",
      "[14,700] loss:0.060\n",
      "[14,800] loss:0.045\n",
      "[14,900] loss:0.051\n",
      "[14,1000] loss:0.065\n",
      "[14,1100] loss:0.035\n",
      "[14,1200] loss:0.053\n",
      "[14,1300] loss:0.033\n",
      "[14,1400] loss:0.051\n",
      "[14,1500] loss:0.021\n",
      "[14,1600] loss:0.050\n",
      "[14,1700] loss:0.057\n",
      "[14,1800] loss:0.065\n",
      "[14,1900] loss:0.061\n",
      "[14,2000] loss:0.045\n",
      "[14,2100] loss:0.032\n",
      "[14,2200] loss:0.038\n",
      "[14,2300] loss:0.041\n",
      "[14,2400] loss:0.036\n",
      "[14,2500] loss:0.050\n",
      "[14,2600] loss:0.036\n",
      "[14,2700] loss:0.054\n",
      "[14,2800] loss:0.059\n",
      "[14,2900] loss:0.036\n",
      "[14,3000] loss:0.031\n",
      "[14,3100] loss:0.019\n",
      "[14,3200] loss:0.048\n",
      "[14,3300] loss:0.032\n",
      "[14,3400] loss:0.041\n",
      "[14,3500] loss:0.048\n",
      "[14,3600] loss:0.046\n",
      "[14,3700] loss:0.063\n",
      "[15,100] loss:0.045\n",
      "[15,200] loss:0.034\n",
      "[15,300] loss:0.028\n",
      "[15,400] loss:0.050\n",
      "[15,500] loss:0.046\n",
      "[15,600] loss:0.042\n",
      "[15,700] loss:0.055\n",
      "[15,800] loss:0.057\n",
      "[15,900] loss:0.044\n",
      "[15,1000] loss:0.045\n",
      "[15,1100] loss:0.022\n",
      "[15,1200] loss:0.036\n",
      "[15,1300] loss:0.021\n",
      "[15,1400] loss:0.034\n",
      "[15,1500] loss:0.051\n",
      "[15,1600] loss:0.040\n",
      "[15,1700] loss:0.041\n",
      "[15,1800] loss:0.042\n",
      "[15,1900] loss:0.054\n",
      "[15,2000] loss:0.053\n",
      "[15,2100] loss:0.045\n",
      "[15,2200] loss:0.059\n",
      "[15,2300] loss:0.026\n",
      "[15,2400] loss:0.066\n",
      "[15,2500] loss:0.042\n",
      "[15,2600] loss:0.058\n",
      "[15,2700] loss:0.043\n",
      "[15,2800] loss:0.045\n",
      "[15,2900] loss:0.051\n",
      "[15,3000] loss:0.062\n",
      "[15,3100] loss:0.045\n",
      "[15,3200] loss:0.055\n",
      "[15,3300] loss:0.029\n",
      "[15,3400] loss:0.030\n",
      "[15,3500] loss:0.049\n",
      "[15,3600] loss:0.051\n",
      "[15,3700] loss:0.060\n",
      "[16,100] loss:0.027\n",
      "[16,200] loss:0.030\n",
      "[16,300] loss:0.052\n",
      "[16,400] loss:0.037\n",
      "[16,500] loss:0.046\n",
      "[16,600] loss:0.041\n",
      "[16,700] loss:0.058\n",
      "[16,800] loss:0.073\n",
      "[16,900] loss:0.038\n",
      "[16,1000] loss:0.042\n",
      "[16,1100] loss:0.028\n",
      "[16,1200] loss:0.055\n",
      "[16,1300] loss:0.043\n",
      "[16,1400] loss:0.042\n",
      "[16,1500] loss:0.049\n",
      "[16,1600] loss:0.068\n",
      "[16,1700] loss:0.053\n",
      "[16,1800] loss:0.053\n",
      "[16,1900] loss:0.048\n",
      "[16,2000] loss:0.034\n",
      "[16,2100] loss:0.069\n",
      "[16,2200] loss:0.025\n",
      "[16,2300] loss:0.045\n",
      "[16,2400] loss:0.039\n",
      "[16,2500] loss:0.030\n",
      "[16,2600] loss:0.026\n",
      "[16,2700] loss:0.042\n",
      "[16,2800] loss:0.036\n",
      "[16,2900] loss:0.039\n",
      "[16,3000] loss:0.024\n",
      "[16,3100] loss:0.054\n",
      "[16,3200] loss:0.060\n",
      "[16,3300] loss:0.049\n",
      "[16,3400] loss:0.035\n",
      "[16,3500] loss:0.037\n",
      "[16,3600] loss:0.017\n",
      "[16,3700] loss:0.033\n",
      "[17,100] loss:0.037\n",
      "[17,200] loss:0.026\n",
      "[17,300] loss:0.040\n",
      "[17,400] loss:0.055\n",
      "[17,500] loss:0.037\n",
      "[17,600] loss:0.037\n",
      "[17,700] loss:0.070\n",
      "[17,800] loss:0.040\n",
      "[17,900] loss:0.045\n",
      "[17,1000] loss:0.028\n",
      "[17,1100] loss:0.051\n",
      "[17,1200] loss:0.043\n",
      "[17,1300] loss:0.054\n",
      "[17,1400] loss:0.037\n",
      "[17,1500] loss:0.027\n",
      "[17,1600] loss:0.059\n",
      "[17,1700] loss:0.048\n",
      "[17,1800] loss:0.023\n",
      "[17,1900] loss:0.032\n",
      "[17,2000] loss:0.066\n",
      "[17,2100] loss:0.046\n",
      "[17,2200] loss:0.053\n",
      "[17,2300] loss:0.065\n",
      "[17,2400] loss:0.032\n",
      "[17,2500] loss:0.035\n",
      "[17,2600] loss:0.037\n",
      "[17,2700] loss:0.036\n",
      "[17,2800] loss:0.029\n",
      "[17,2900] loss:0.032\n",
      "[17,3000] loss:0.059\n",
      "[17,3100] loss:0.047\n",
      "[17,3200] loss:0.043\n",
      "[17,3300] loss:0.040\n",
      "[17,3400] loss:0.032\n",
      "[17,3500] loss:0.039\n",
      "[17,3600] loss:0.055\n",
      "[17,3700] loss:0.042\n",
      "[18,100] loss:0.036\n",
      "[18,200] loss:0.030\n",
      "[18,300] loss:0.037\n",
      "[18,400] loss:0.030\n",
      "[18,500] loss:0.040\n",
      "[18,600] loss:0.041\n",
      "[18,700] loss:0.062\n",
      "[18,800] loss:0.037\n",
      "[18,900] loss:0.042\n",
      "[18,1000] loss:0.061\n",
      "[18,1100] loss:0.033\n",
      "[18,1200] loss:0.022\n",
      "[18,1300] loss:0.049\n",
      "[18,1400] loss:0.041\n",
      "[18,1500] loss:0.050\n",
      "[18,1600] loss:0.057\n",
      "[18,1700] loss:0.066\n",
      "[18,1800] loss:0.044\n",
      "[18,1900] loss:0.034\n",
      "[18,2000] loss:0.037\n",
      "[18,2100] loss:0.047\n",
      "[18,2200] loss:0.031\n",
      "[18,2300] loss:0.055\n",
      "[18,2400] loss:0.050\n",
      "[18,2500] loss:0.027\n",
      "[18,2600] loss:0.047\n",
      "[18,2700] loss:0.056\n",
      "[18,2800] loss:0.055\n",
      "[18,2900] loss:0.035\n",
      "[18,3000] loss:0.036\n",
      "[18,3100] loss:0.049\n",
      "[18,3200] loss:0.054\n",
      "[18,3300] loss:0.024\n",
      "[18,3400] loss:0.051\n",
      "[18,3500] loss:0.034\n",
      "[18,3600] loss:0.050\n",
      "[18,3700] loss:0.039\n",
      "[19,100] loss:0.036\n",
      "[19,200] loss:0.047\n",
      "[19,300] loss:0.056\n",
      "[19,400] loss:0.063\n",
      "[19,500] loss:0.032\n",
      "[19,600] loss:0.031\n",
      "[19,700] loss:0.023\n",
      "[19,800] loss:0.049\n",
      "[19,900] loss:0.045\n",
      "[19,1000] loss:0.050\n",
      "[19,1100] loss:0.038\n",
      "[19,1200] loss:0.036\n",
      "[19,1300] loss:0.037\n",
      "[19,1400] loss:0.032\n",
      "[19,1500] loss:0.025\n",
      "[19,1600] loss:0.028\n",
      "[19,1700] loss:0.055\n",
      "[19,1800] loss:0.043\n",
      "[19,1900] loss:0.040\n",
      "[19,2000] loss:0.036\n",
      "[19,2100] loss:0.054\n",
      "[19,2200] loss:0.037\n",
      "[19,2300] loss:0.036\n",
      "[19,2400] loss:0.048\n",
      "[19,2500] loss:0.052\n",
      "[19,2600] loss:0.051\n",
      "[19,2700] loss:0.032\n",
      "[19,2800] loss:0.054\n",
      "[19,2900] loss:0.043\n",
      "[19,3000] loss:0.040\n",
      "[19,3100] loss:0.039\n",
      "[19,3200] loss:0.027\n",
      "[19,3300] loss:0.023\n",
      "[19,3400] loss:0.044\n",
      "[19,3500] loss:0.036\n",
      "[19,3600] loss:0.065\n",
      "[19,3700] loss:0.037\n",
      "[20,100] loss:0.024\n",
      "[20,200] loss:0.037\n",
      "[20,300] loss:0.048\n",
      "[20,400] loss:0.033\n",
      "[20,500] loss:0.040\n",
      "[20,600] loss:0.028\n",
      "[20,700] loss:0.055\n",
      "[20,800] loss:0.046\n",
      "[20,900] loss:0.067\n",
      "[20,1000] loss:0.042\n",
      "[20,1100] loss:0.050\n",
      "[20,1200] loss:0.026\n",
      "[20,1300] loss:0.041\n",
      "[20,1400] loss:0.034\n",
      "[20,1500] loss:0.057\n",
      "[20,1600] loss:0.064\n",
      "[20,1700] loss:0.061\n",
      "[20,1800] loss:0.028\n",
      "[20,1900] loss:0.035\n",
      "[20,2000] loss:0.042\n",
      "[20,2100] loss:0.047\n",
      "[20,2200] loss:0.023\n",
      "[20,2300] loss:0.028\n",
      "[20,2400] loss:0.044\n",
      "[20,2500] loss:0.031\n",
      "[20,2600] loss:0.041\n",
      "[20,2700] loss:0.026\n",
      "[20,2800] loss:0.041\n",
      "[20,2900] loss:0.053\n",
      "[20,3000] loss:0.045\n",
      "[20,3100] loss:0.049\n",
      "[20,3200] loss:0.053\n",
      "[20,3300] loss:0.035\n",
      "[20,3400] loss:0.039\n",
      "[20,3500] loss:0.023\n",
      "[20,3600] loss:0.050\n",
      "[20,3700] loss:0.049\n",
      "[21,100] loss:0.043\n",
      "[21,200] loss:0.028\n",
      "[21,300] loss:0.058\n",
      "[21,400] loss:0.039\n",
      "[21,500] loss:0.041\n",
      "[21,600] loss:0.037\n",
      "[21,700] loss:0.040\n",
      "[21,800] loss:0.037\n",
      "[21,900] loss:0.037\n",
      "[21,1000] loss:0.033\n",
      "[21,1100] loss:0.032\n",
      "[21,1200] loss:0.031\n",
      "[21,1300] loss:0.039\n",
      "[21,1400] loss:0.031\n",
      "[21,1500] loss:0.039\n",
      "[21,1600] loss:0.054\n",
      "[21,1700] loss:0.039\n",
      "[21,1800] loss:0.039\n",
      "[21,1900] loss:0.033\n",
      "[21,2000] loss:0.031\n",
      "[21,2100] loss:0.040\n",
      "[21,2200] loss:0.041\n",
      "[21,2300] loss:0.046\n",
      "[21,2400] loss:0.022\n",
      "[21,2500] loss:0.054\n",
      "[21,2600] loss:0.035\n",
      "[21,2700] loss:0.034\n",
      "[21,2800] loss:0.032\n",
      "[21,2900] loss:0.041\n",
      "[21,3000] loss:0.031\n",
      "[21,3100] loss:0.043\n",
      "[21,3200] loss:0.016\n",
      "[21,3300] loss:0.053\n",
      "[21,3400] loss:0.060\n",
      "[21,3500] loss:0.037\n",
      "[21,3600] loss:0.026\n",
      "[21,3700] loss:0.050\n",
      "[22,100] loss:0.049\n",
      "[22,200] loss:0.027\n",
      "[22,300] loss:0.055\n",
      "[22,400] loss:0.043\n",
      "[22,500] loss:0.032\n",
      "[22,600] loss:0.028\n",
      "[22,700] loss:0.028\n",
      "[22,800] loss:0.032\n",
      "[22,900] loss:0.024\n",
      "[22,1000] loss:0.043\n",
      "[22,1100] loss:0.031\n",
      "[22,1200] loss:0.028\n",
      "[22,1300] loss:0.060\n",
      "[22,1400] loss:0.041\n",
      "[22,1500] loss:0.029\n",
      "[22,1600] loss:0.032\n",
      "[22,1700] loss:0.023\n",
      "[22,1800] loss:0.049\n",
      "[22,1900] loss:0.027\n",
      "[22,2000] loss:0.035\n",
      "[22,2100] loss:0.042\n",
      "[22,2200] loss:0.051\n",
      "[22,2300] loss:0.030\n",
      "[22,2400] loss:0.035\n",
      "[22,2500] loss:0.037\n",
      "[22,2600] loss:0.039\n",
      "[22,2700] loss:0.042\n",
      "[22,2800] loss:0.046\n",
      "[22,2900] loss:0.030\n",
      "[22,3000] loss:0.059\n",
      "[22,3100] loss:0.043\n",
      "[22,3200] loss:0.033\n",
      "[22,3300] loss:0.039\n",
      "[22,3400] loss:0.023\n",
      "[22,3500] loss:0.031\n",
      "[22,3600] loss:0.042\n",
      "[22,3700] loss:0.023\n",
      "[23,100] loss:0.072\n",
      "[23,200] loss:0.052\n",
      "[23,300] loss:0.026\n",
      "[23,400] loss:0.036\n",
      "[23,500] loss:0.016\n",
      "[23,600] loss:0.030\n",
      "[23,700] loss:0.038\n",
      "[23,800] loss:0.025\n",
      "[23,900] loss:0.047\n",
      "[23,1000] loss:0.025\n",
      "[23,1100] loss:0.053\n",
      "[23,1200] loss:0.050\n",
      "[23,1300] loss:0.013\n",
      "[23,1400] loss:0.038\n",
      "[23,1500] loss:0.031\n",
      "[23,1600] loss:0.035\n",
      "[23,1700] loss:0.027\n",
      "[23,1800] loss:0.034\n",
      "[23,1900] loss:0.025\n",
      "[23,2000] loss:0.033\n",
      "[23,2100] loss:0.059\n",
      "[23,2200] loss:0.025\n",
      "[23,2300] loss:0.018\n",
      "[23,2400] loss:0.059\n",
      "[23,2500] loss:0.053\n",
      "[23,2600] loss:0.045\n",
      "[23,2700] loss:0.037\n",
      "[23,2800] loss:0.048\n",
      "[23,2900] loss:0.038\n",
      "[23,3000] loss:0.051\n",
      "[23,3100] loss:0.039\n",
      "[23,3200] loss:0.041\n",
      "[23,3300] loss:0.025\n",
      "[23,3400] loss:0.040\n",
      "[23,3500] loss:0.050\n",
      "[23,3600] loss:0.029\n",
      "[23,3700] loss:0.084\n",
      "[24,100] loss:0.025\n",
      "[24,200] loss:0.042\n",
      "[24,300] loss:0.042\n",
      "[24,400] loss:0.025\n",
      "[24,500] loss:0.037\n",
      "[24,600] loss:0.046\n",
      "[24,700] loss:0.019\n",
      "[24,800] loss:0.041\n",
      "[24,900] loss:0.034\n",
      "[24,1000] loss:0.026\n",
      "[24,1100] loss:0.058\n",
      "[24,1200] loss:0.050\n",
      "[24,1300] loss:0.069\n",
      "[24,1400] loss:0.020\n",
      "[24,1500] loss:0.045\n",
      "[24,1600] loss:0.024\n",
      "[24,1700] loss:0.034\n",
      "[24,1800] loss:0.041\n",
      "[24,1900] loss:0.048\n",
      "[24,2000] loss:0.037\n",
      "[24,2100] loss:0.020\n",
      "[24,2200] loss:0.043\n",
      "[24,2300] loss:0.029\n",
      "[24,2400] loss:0.017\n",
      "[24,2500] loss:0.025\n",
      "[24,2600] loss:0.044\n",
      "[24,2700] loss:0.042\n",
      "[24,2800] loss:0.043\n",
      "[24,2900] loss:0.054\n",
      "[24,3000] loss:0.042\n",
      "[24,3100] loss:0.046\n",
      "[24,3200] loss:0.029\n",
      "[24,3300] loss:0.034\n",
      "[24,3400] loss:0.036\n",
      "[24,3500] loss:0.030\n",
      "[24,3600] loss:0.030\n",
      "[24,3700] loss:0.037\n",
      "[25,100] loss:0.021\n",
      "[25,200] loss:0.031\n",
      "[25,300] loss:0.041\n",
      "[25,400] loss:0.048\n",
      "[25,500] loss:0.041\n",
      "[25,600] loss:0.036\n",
      "[25,700] loss:0.019\n",
      "[25,800] loss:0.028\n",
      "[25,900] loss:0.054\n",
      "[25,1000] loss:0.044\n",
      "[25,1100] loss:0.058\n",
      "[25,1200] loss:0.034\n",
      "[25,1300] loss:0.037\n",
      "[25,1400] loss:0.039\n",
      "[25,1500] loss:0.029\n",
      "[25,1600] loss:0.031\n",
      "[25,1700] loss:0.024\n",
      "[25,1800] loss:0.035\n",
      "[25,1900] loss:0.036\n",
      "[25,2000] loss:0.028\n",
      "[25,2100] loss:0.035\n",
      "[25,2200] loss:0.038\n",
      "[25,2300] loss:0.067\n",
      "[25,2400] loss:0.039\n",
      "[25,2500] loss:0.053\n",
      "[25,2600] loss:0.036\n",
      "[25,2700] loss:0.023\n",
      "[25,2800] loss:0.036\n",
      "[25,2900] loss:0.031\n",
      "[25,3000] loss:0.022\n",
      "[25,3100] loss:0.055\n",
      "[25,3200] loss:0.034\n",
      "[25,3300] loss:0.026\n",
      "[25,3400] loss:0.060\n",
      "[25,3500] loss:0.047\n",
      "[25,3600] loss:0.031\n",
      "[25,3700] loss:0.045\n",
      "[26,100] loss:0.044\n",
      "[26,200] loss:0.020\n",
      "[26,300] loss:0.040\n",
      "[26,400] loss:0.030\n",
      "[26,500] loss:0.062\n",
      "[26,600] loss:0.039\n",
      "[26,700] loss:0.031\n",
      "[26,800] loss:0.025\n",
      "[26,900] loss:0.026\n",
      "[26,1000] loss:0.044\n",
      "[26,1100] loss:0.044\n",
      "[26,1200] loss:0.026\n",
      "[26,1300] loss:0.041\n",
      "[26,1400] loss:0.046\n",
      "[26,1500] loss:0.051\n",
      "[26,1600] loss:0.040\n",
      "[26,1700] loss:0.029\n",
      "[26,1800] loss:0.030\n",
      "[26,1900] loss:0.024\n",
      "[26,2000] loss:0.049\n",
      "[26,2100] loss:0.034\n",
      "[26,2200] loss:0.018\n",
      "[26,2300] loss:0.042\n",
      "[26,2400] loss:0.030\n",
      "[26,2500] loss:0.032\n",
      "[26,2600] loss:0.039\n",
      "[26,2700] loss:0.027\n",
      "[26,2800] loss:0.042\n",
      "[26,2900] loss:0.036\n",
      "[26,3000] loss:0.032\n",
      "[26,3100] loss:0.040\n",
      "[26,3200] loss:0.037\n",
      "[26,3300] loss:0.046\n",
      "[26,3400] loss:0.028\n",
      "[26,3500] loss:0.036\n",
      "[26,3600] loss:0.044\n",
      "[26,3700] loss:0.075\n",
      "[27,100] loss:0.042\n",
      "[27,200] loss:0.050\n",
      "[27,300] loss:0.020\n",
      "[27,400] loss:0.027\n",
      "[27,500] loss:0.023\n",
      "[27,600] loss:0.022\n",
      "[27,700] loss:0.031\n",
      "[27,800] loss:0.061\n",
      "[27,900] loss:0.043\n",
      "[27,1000] loss:0.051\n",
      "[27,1100] loss:0.050\n",
      "[27,1200] loss:0.026\n",
      "[27,1300] loss:0.068\n",
      "[27,1400] loss:0.044\n",
      "[27,1500] loss:0.050\n",
      "[27,1600] loss:0.039\n",
      "[27,1700] loss:0.041\n",
      "[27,1800] loss:0.037\n",
      "[27,1900] loss:0.024\n",
      "[27,2000] loss:0.058\n",
      "[27,2100] loss:0.036\n",
      "[27,2200] loss:0.037\n",
      "[27,2300] loss:0.025\n",
      "[27,2400] loss:0.045\n",
      "[27,2500] loss:0.034\n",
      "[27,2600] loss:0.015\n",
      "[27,2700] loss:0.039\n",
      "[27,2800] loss:0.019\n",
      "[27,2900] loss:0.056\n",
      "[27,3000] loss:0.027\n",
      "[27,3100] loss:0.044\n",
      "[27,3200] loss:0.045\n",
      "[27,3300] loss:0.052\n",
      "[27,3400] loss:0.032\n",
      "[27,3500] loss:0.034\n",
      "[27,3600] loss:0.036\n",
      "[27,3700] loss:0.040\n",
      "[28,100] loss:0.035\n",
      "[28,200] loss:0.059\n",
      "[28,300] loss:0.030\n",
      "[28,400] loss:0.026\n",
      "[28,500] loss:0.048\n",
      "[28,600] loss:0.037\n",
      "[28,700] loss:0.025\n",
      "[28,800] loss:0.018\n",
      "[28,900] loss:0.025\n",
      "[28,1000] loss:0.045\n",
      "[28,1100] loss:0.034\n",
      "[28,1200] loss:0.048\n",
      "[28,1300] loss:0.054\n",
      "[28,1400] loss:0.037\n",
      "[28,1500] loss:0.056\n",
      "[28,1600] loss:0.032\n",
      "[28,1700] loss:0.053\n",
      "[28,1800] loss:0.049\n",
      "[28,1900] loss:0.041\n",
      "[28,2000] loss:0.036\n",
      "[28,2100] loss:0.043\n",
      "[28,2200] loss:0.064\n",
      "[28,2300] loss:0.049\n",
      "[28,2400] loss:0.082\n",
      "[28,2500] loss:0.051\n",
      "[28,2600] loss:0.022\n",
      "[28,2700] loss:0.035\n",
      "[28,2800] loss:0.059\n",
      "[28,2900] loss:0.028\n",
      "[28,3000] loss:0.020\n",
      "[28,3100] loss:0.027\n",
      "[28,3200] loss:0.059\n",
      "[28,3300] loss:0.031\n",
      "[28,3400] loss:0.039\n",
      "[28,3500] loss:0.043\n",
      "[28,3600] loss:0.027\n",
      "[28,3700] loss:0.024\n",
      "[29,100] loss:0.028\n",
      "[29,200] loss:0.032\n",
      "[29,300] loss:0.018\n",
      "[29,400] loss:0.062\n",
      "[29,500] loss:0.039\n",
      "[29,600] loss:0.040\n",
      "[29,700] loss:0.039\n",
      "[29,800] loss:0.049\n",
      "[29,900] loss:0.041\n",
      "[29,1000] loss:0.019\n",
      "[29,1100] loss:0.023\n",
      "[29,1200] loss:0.019\n",
      "[29,1300] loss:0.029\n",
      "[29,1400] loss:0.041\n",
      "[29,1500] loss:0.026\n",
      "[29,1600] loss:0.024\n",
      "[29,1700] loss:0.030\n",
      "[29,1800] loss:0.055\n",
      "[29,1900] loss:0.021\n",
      "[29,2000] loss:0.051\n",
      "[29,2100] loss:0.034\n",
      "[29,2200] loss:0.033\n",
      "[29,2300] loss:0.031\n",
      "[29,2400] loss:0.035\n",
      "[29,2500] loss:0.051\n",
      "[29,2600] loss:0.040\n",
      "[29,2700] loss:0.037\n",
      "[29,2800] loss:0.043\n",
      "[29,2900] loss:0.034\n",
      "[29,3000] loss:0.056\n",
      "[29,3100] loss:0.048\n",
      "[29,3200] loss:0.032\n",
      "[29,3300] loss:0.023\n",
      "[29,3400] loss:0.061\n",
      "[29,3500] loss:0.033\n",
      "[29,3600] loss:0.032\n",
      "[29,3700] loss:0.034\n",
      "[30,100] loss:0.036\n",
      "[30,200] loss:0.049\n",
      "[30,300] loss:0.044\n",
      "[30,400] loss:0.043\n",
      "[30,500] loss:0.028\n",
      "[30,600] loss:0.053\n",
      "[30,700] loss:0.064\n",
      "[30,800] loss:0.038\n",
      "[30,900] loss:0.067\n",
      "[30,1000] loss:0.036\n",
      "[30,1100] loss:0.036\n",
      "[30,1200] loss:0.039\n",
      "[30,1300] loss:0.024\n",
      "[30,1400] loss:0.030\n",
      "[30,1500] loss:0.034\n",
      "[30,1600] loss:0.033\n",
      "[30,1700] loss:0.022\n",
      "[30,1800] loss:0.030\n",
      "[30,1900] loss:0.068\n",
      "[30,2000] loss:0.026\n",
      "[30,2100] loss:0.044\n",
      "[30,2200] loss:0.037\n",
      "[30,2300] loss:0.036\n",
      "[30,2400] loss:0.056\n",
      "[30,2500] loss:0.034\n",
      "[30,2600] loss:0.033\n",
      "[30,2700] loss:0.016\n",
      "[30,2800] loss:0.050\n",
      "[30,2900] loss:0.053\n",
      "[30,3000] loss:0.018\n",
      "[30,3100] loss:0.020\n",
      "[30,3200] loss:0.049\n",
      "[30,3300] loss:0.029\n",
      "[30,3400] loss:0.031\n",
      "[30,3500] loss:0.031\n",
      "[30,3600] loss:0.046\n",
      "[30,3700] loss:0.028\n",
      "[31,100] loss:0.028\n",
      "[31,200] loss:0.043\n",
      "[31,300] loss:0.038\n",
      "[31,400] loss:0.026\n",
      "[31,500] loss:0.019\n",
      "[31,600] loss:0.040\n",
      "[31,700] loss:0.036\n",
      "[31,800] loss:0.035\n",
      "[31,900] loss:0.035\n",
      "[31,1000] loss:0.059\n",
      "[31,1100] loss:0.021\n",
      "[31,1200] loss:0.058\n",
      "[31,1300] loss:0.036\n",
      "[31,1400] loss:0.051\n",
      "[31,1500] loss:0.030\n",
      "[31,1600] loss:0.022\n",
      "[31,1700] loss:0.045\n",
      "[31,1800] loss:0.034\n",
      "[31,1900] loss:0.025\n",
      "[31,2000] loss:0.010\n",
      "[31,2100] loss:0.043\n",
      "[31,2200] loss:0.015\n",
      "[31,2300] loss:0.045\n",
      "[31,2400] loss:0.017\n",
      "[31,2500] loss:0.026\n",
      "[31,2600] loss:0.041\n",
      "[31,2700] loss:0.050\n",
      "[31,2800] loss:0.029\n",
      "[31,2900] loss:0.044\n",
      "[31,3000] loss:0.031\n",
      "[31,3100] loss:0.025\n",
      "[31,3200] loss:0.021\n",
      "[31,3300] loss:0.040\n",
      "[31,3400] loss:0.024\n",
      "[31,3500] loss:0.065\n",
      "[31,3600] loss:0.049\n",
      "[31,3700] loss:0.023\n",
      "[32,100] loss:0.063\n",
      "[32,200] loss:0.041\n",
      "[32,300] loss:0.051\n",
      "[32,400] loss:0.037\n",
      "[32,500] loss:0.025\n",
      "[32,600] loss:0.022\n",
      "[32,700] loss:0.033\n",
      "[32,800] loss:0.036\n",
      "[32,900] loss:0.061\n",
      "[32,1000] loss:0.040\n",
      "[32,1100] loss:0.037\n",
      "[32,1200] loss:0.033\n",
      "[32,1300] loss:0.041\n",
      "[32,1400] loss:0.032\n",
      "[32,1500] loss:0.019\n",
      "[32,1600] loss:0.033\n",
      "[32,1700] loss:0.028\n",
      "[32,1800] loss:0.036\n",
      "[32,1900] loss:0.027\n",
      "[32,2000] loss:0.037\n",
      "[32,2100] loss:0.020\n",
      "[32,2200] loss:0.048\n",
      "[32,2300] loss:0.032\n",
      "[32,2400] loss:0.050\n",
      "[32,2500] loss:0.025\n",
      "[32,2600] loss:0.054\n",
      "[32,2700] loss:0.041\n",
      "[32,2800] loss:0.048\n",
      "[32,2900] loss:0.042\n",
      "[32,3000] loss:0.068\n",
      "[32,3100] loss:0.048\n",
      "[32,3200] loss:0.022\n",
      "[32,3300] loss:0.043\n",
      "[32,3400] loss:0.033\n",
      "[32,3500] loss:0.055\n",
      "[32,3600] loss:0.049\n",
      "[32,3700] loss:0.067\n",
      "[33,100] loss:0.051\n",
      "[33,200] loss:0.065\n",
      "[33,300] loss:0.027\n",
      "[33,400] loss:0.027\n",
      "[33,500] loss:0.031\n",
      "[33,600] loss:0.037\n",
      "[33,700] loss:0.039\n",
      "[33,800] loss:0.033\n",
      "[33,900] loss:0.038\n",
      "[33,1000] loss:0.036\n",
      "[33,1100] loss:0.022\n",
      "[33,1200] loss:0.043\n",
      "[33,1300] loss:0.052\n",
      "[33,1400] loss:0.037\n",
      "[33,1500] loss:0.023\n",
      "[33,1600] loss:0.039\n",
      "[33,1700] loss:0.022\n",
      "[33,1800] loss:0.014\n",
      "[33,1900] loss:0.027\n",
      "[33,2000] loss:0.031\n",
      "[33,2100] loss:0.029\n",
      "[33,2200] loss:0.038\n",
      "[33,2300] loss:0.055\n",
      "[33,2400] loss:0.033\n",
      "[33,2500] loss:0.032\n",
      "[33,2600] loss:0.028\n",
      "[33,2700] loss:0.023\n",
      "[33,2800] loss:0.037\n",
      "[33,2900] loss:0.043\n",
      "[33,3000] loss:0.024\n",
      "[33,3100] loss:0.027\n",
      "[33,3200] loss:0.050\n",
      "[33,3300] loss:0.058\n",
      "[33,3400] loss:0.021\n",
      "[33,3500] loss:0.060\n",
      "[33,3600] loss:0.038\n",
      "[33,3700] loss:0.063\n",
      "[34,100] loss:0.024\n",
      "[34,200] loss:0.040\n",
      "[34,300] loss:0.030\n",
      "[34,400] loss:0.077\n",
      "[34,500] loss:0.039\n",
      "[34,600] loss:0.026\n",
      "[34,700] loss:0.037\n",
      "[34,800] loss:0.048\n",
      "[34,900] loss:0.033\n",
      "[34,1000] loss:0.037\n",
      "[34,1100] loss:0.026\n",
      "[34,1200] loss:0.035\n",
      "[34,1300] loss:0.041\n",
      "[34,1400] loss:0.039\n",
      "[34,1500] loss:0.047\n",
      "[34,1600] loss:0.033\n",
      "[34,1700] loss:0.051\n",
      "[34,1800] loss:0.019\n",
      "[34,1900] loss:0.048\n",
      "[34,2000] loss:0.025\n",
      "[34,2100] loss:0.029\n",
      "[34,2200] loss:0.029\n",
      "[34,2300] loss:0.052\n",
      "[34,2400] loss:0.050\n",
      "[34,2500] loss:0.026\n",
      "[34,2600] loss:0.027\n",
      "[34,2700] loss:0.030\n",
      "[34,2800] loss:0.042\n",
      "[34,2900] loss:0.013\n",
      "[34,3000] loss:0.027\n",
      "[34,3100] loss:0.045\n",
      "[34,3200] loss:0.036\n",
      "[34,3300] loss:0.039\n",
      "[34,3400] loss:0.025\n",
      "[34,3500] loss:0.052\n",
      "[34,3600] loss:0.034\n",
      "[34,3700] loss:0.033\n",
      "[35,100] loss:0.026\n",
      "[35,200] loss:0.032\n",
      "[35,300] loss:0.050\n",
      "[35,400] loss:0.031\n",
      "[35,500] loss:0.027\n",
      "[35,600] loss:0.027\n",
      "[35,700] loss:0.039\n",
      "[35,800] loss:0.058\n",
      "[35,900] loss:0.031\n",
      "[35,1000] loss:0.026\n",
      "[35,1100] loss:0.029\n",
      "[35,1200] loss:0.032\n",
      "[35,1300] loss:0.049\n",
      "[35,1400] loss:0.033\n",
      "[35,1500] loss:0.029\n",
      "[35,1600] loss:0.026\n",
      "[35,1700] loss:0.017\n",
      "[35,1800] loss:0.021\n",
      "[35,1900] loss:0.040\n",
      "[35,2000] loss:0.047\n",
      "[35,2100] loss:0.043\n",
      "[35,2200] loss:0.034\n",
      "[35,2300] loss:0.024\n",
      "[35,2400] loss:0.035\n",
      "[35,2500] loss:0.022\n",
      "[35,2600] loss:0.023\n",
      "[35,2700] loss:0.047\n",
      "[35,2800] loss:0.059\n",
      "[35,2900] loss:0.040\n",
      "[35,3000] loss:0.037\n",
      "[35,3100] loss:0.041\n",
      "[35,3200] loss:0.027\n",
      "[35,3300] loss:0.053\n",
      "[35,3400] loss:0.019\n",
      "[35,3500] loss:0.031\n",
      "[35,3600] loss:0.031\n",
      "[35,3700] loss:0.024\n",
      "[36,100] loss:0.021\n",
      "[36,200] loss:0.047\n",
      "[36,300] loss:0.020\n",
      "[36,400] loss:0.025\n",
      "[36,500] loss:0.023\n",
      "[36,600] loss:0.036\n",
      "[36,700] loss:0.067\n",
      "[36,800] loss:0.030\n",
      "[36,900] loss:0.032\n",
      "[36,1000] loss:0.042\n",
      "[36,1100] loss:0.031\n",
      "[36,1200] loss:0.079\n",
      "[36,1300] loss:0.033\n",
      "[36,1400] loss:0.040\n",
      "[36,1500] loss:0.056\n",
      "[36,1600] loss:0.058\n",
      "[36,1700] loss:0.038\n",
      "[36,1800] loss:0.027\n",
      "[36,1900] loss:0.017\n",
      "[36,2000] loss:0.018\n",
      "[36,2100] loss:0.049\n",
      "[36,2200] loss:0.029\n",
      "[36,2300] loss:0.042\n",
      "[36,2400] loss:0.048\n",
      "[36,2500] loss:0.027\n",
      "[36,2600] loss:0.038\n",
      "[36,2700] loss:0.052\n",
      "[36,2800] loss:0.021\n",
      "[36,2900] loss:0.042\n",
      "[36,3000] loss:0.023\n",
      "[36,3100] loss:0.031\n",
      "[36,3200] loss:0.030\n",
      "[36,3300] loss:0.052\n",
      "[36,3400] loss:0.018\n",
      "[36,3500] loss:0.029\n",
      "[36,3600] loss:0.042\n",
      "[36,3700] loss:0.034\n",
      "[37,100] loss:0.037\n",
      "[37,200] loss:0.027\n",
      "[37,300] loss:0.031\n",
      "[37,400] loss:0.031\n",
      "[37,500] loss:0.039\n",
      "[37,600] loss:0.049\n",
      "[37,700] loss:0.036\n",
      "[37,800] loss:0.040\n",
      "[37,900] loss:0.037\n",
      "[37,1000] loss:0.029\n",
      "[37,1100] loss:0.057\n",
      "[37,1200] loss:0.022\n",
      "[37,1300] loss:0.017\n",
      "[37,1400] loss:0.027\n",
      "[37,1500] loss:0.034\n",
      "[37,1600] loss:0.040\n",
      "[37,1700] loss:0.028\n",
      "[37,1800] loss:0.061\n",
      "[37,1900] loss:0.020\n",
      "[37,2000] loss:0.036\n",
      "[37,2100] loss:0.041\n",
      "[37,2200] loss:0.048\n",
      "[37,2300] loss:0.046\n",
      "[37,2400] loss:0.071\n",
      "[37,2500] loss:0.041\n",
      "[37,2600] loss:0.028\n",
      "[37,2700] loss:0.028\n",
      "[37,2800] loss:0.033\n",
      "[37,2900] loss:0.038\n",
      "[37,3000] loss:0.029\n",
      "[37,3100] loss:0.014\n",
      "[37,3200] loss:0.046\n",
      "[37,3300] loss:0.053\n",
      "[37,3400] loss:0.036\n",
      "[37,3500] loss:0.039\n",
      "[37,3600] loss:0.048\n",
      "[37,3700] loss:0.030\n",
      "[38,100] loss:0.041\n",
      "[38,200] loss:0.048\n",
      "[38,300] loss:0.027\n",
      "[38,400] loss:0.028\n",
      "[38,500] loss:0.028\n",
      "[38,600] loss:0.028\n",
      "[38,700] loss:0.037\n",
      "[38,800] loss:0.040\n",
      "[38,900] loss:0.028\n",
      "[38,1000] loss:0.036\n",
      "[38,1100] loss:0.036\n",
      "[38,1200] loss:0.041\n",
      "[38,1300] loss:0.036\n",
      "[38,1400] loss:0.025\n",
      "[38,1500] loss:0.019\n",
      "[38,1600] loss:0.024\n",
      "[38,1700] loss:0.043\n",
      "[38,1800] loss:0.045\n",
      "[38,1900] loss:0.027\n",
      "[38,2000] loss:0.033\n",
      "[38,2100] loss:0.034\n",
      "[38,2200] loss:0.037\n",
      "[38,2300] loss:0.061\n",
      "[38,2400] loss:0.029\n",
      "[38,2500] loss:0.025\n",
      "[38,2600] loss:0.031\n",
      "[38,2700] loss:0.050\n",
      "[38,2800] loss:0.052\n",
      "[38,2900] loss:0.037\n",
      "[38,3000] loss:0.019\n",
      "[38,3100] loss:0.043\n",
      "[38,3200] loss:0.044\n",
      "[38,3300] loss:0.060\n",
      "[38,3400] loss:0.023\n",
      "[38,3500] loss:0.041\n",
      "[38,3600] loss:0.018\n",
      "[38,3700] loss:0.054\n",
      "[39,100] loss:0.064\n",
      "[39,200] loss:0.035\n",
      "[39,300] loss:0.029\n",
      "[39,400] loss:0.056\n",
      "[39,500] loss:0.040\n",
      "[39,600] loss:0.040\n",
      "[39,700] loss:0.022\n",
      "[39,800] loss:0.048\n",
      "[39,900] loss:0.028\n",
      "[39,1000] loss:0.023\n",
      "[39,1100] loss:0.032\n",
      "[39,1200] loss:0.025\n",
      "[39,1300] loss:0.050\n",
      "[39,1400] loss:0.026\n",
      "[39,1500] loss:0.029\n",
      "[39,1600] loss:0.044\n",
      "[39,1700] loss:0.035\n",
      "[39,1800] loss:0.022\n",
      "[39,1900] loss:0.030\n",
      "[39,2000] loss:0.034\n",
      "[39,2100] loss:0.044\n",
      "[39,2200] loss:0.013\n",
      "[39,2300] loss:0.043\n",
      "[39,2400] loss:0.022\n",
      "[39,2500] loss:0.036\n",
      "[39,2600] loss:0.027\n",
      "[39,2700] loss:0.016\n",
      "[39,2800] loss:0.061\n",
      "[39,2900] loss:0.018\n",
      "[39,3000] loss:0.072\n",
      "[39,3100] loss:0.052\n",
      "[39,3200] loss:0.043\n",
      "[39,3300] loss:0.057\n",
      "[39,3400] loss:0.023\n",
      "[39,3500] loss:0.034\n",
      "[39,3600] loss:0.028\n",
      "[39,3700] loss:0.049\n",
      "[40,100] loss:0.026\n",
      "[40,200] loss:0.021\n",
      "[40,300] loss:0.028\n",
      "[40,400] loss:0.045\n",
      "[40,500] loss:0.042\n",
      "[40,600] loss:0.079\n",
      "[40,700] loss:0.064\n",
      "[40,800] loss:0.042\n",
      "[40,900] loss:0.028\n",
      "[40,1000] loss:0.036\n",
      "[40,1100] loss:0.049\n",
      "[40,1200] loss:0.023\n",
      "[40,1300] loss:0.032\n",
      "[40,1400] loss:0.041\n",
      "[40,1500] loss:0.053\n",
      "[40,1600] loss:0.084\n",
      "[40,1700] loss:0.040\n",
      "[40,1800] loss:0.024\n",
      "[40,1900] loss:0.029\n",
      "[40,2000] loss:0.045\n",
      "[40,2100] loss:0.040\n",
      "[40,2200] loss:0.042\n",
      "[40,2300] loss:0.039\n",
      "[40,2400] loss:0.037\n",
      "[40,2500] loss:0.032\n",
      "[40,2600] loss:0.056\n",
      "[40,2700] loss:0.034\n",
      "[40,2800] loss:0.040\n",
      "[40,2900] loss:0.051\n",
      "[40,3000] loss:0.037\n",
      "[40,3100] loss:0.020\n",
      "[40,3200] loss:0.029\n",
      "[40,3300] loss:0.035\n",
      "[40,3400] loss:0.036\n",
      "[40,3500] loss:0.051\n",
      "[40,3600] loss:0.027\n",
      "[40,3700] loss:0.051\n",
      "[41,100] loss:0.020\n",
      "[41,200] loss:0.049\n",
      "[41,300] loss:0.029\n",
      "[41,400] loss:0.033\n",
      "[41,500] loss:0.033\n",
      "[41,600] loss:0.046\n",
      "[41,700] loss:0.032\n",
      "[41,800] loss:0.052\n",
      "[41,900] loss:0.036\n",
      "[41,1000] loss:0.027\n",
      "[41,1100] loss:0.051\n",
      "[41,1200] loss:0.036\n",
      "[41,1300] loss:0.033\n",
      "[41,1400] loss:0.021\n",
      "[41,1500] loss:0.055\n",
      "[41,1600] loss:0.058\n",
      "[41,1700] loss:0.049\n",
      "[41,1800] loss:0.036\n",
      "[41,1900] loss:0.031\n",
      "[41,2000] loss:0.039\n",
      "[41,2100] loss:0.029\n",
      "[41,2200] loss:0.017\n",
      "[41,2300] loss:0.019\n",
      "[41,2400] loss:0.040\n",
      "[41,2500] loss:0.033\n",
      "[41,2600] loss:0.022\n",
      "[41,2700] loss:0.071\n",
      "[41,2800] loss:0.031\n",
      "[41,2900] loss:0.052\n",
      "[41,3000] loss:0.050\n",
      "[41,3100] loss:0.051\n",
      "[41,3200] loss:0.033\n",
      "[41,3300] loss:0.014\n",
      "[41,3400] loss:0.061\n",
      "[41,3500] loss:0.024\n",
      "[41,3600] loss:0.025\n",
      "[41,3700] loss:0.045\n",
      "[42,100] loss:0.028\n",
      "[42,200] loss:0.042\n",
      "[42,300] loss:0.028\n",
      "[42,400] loss:0.021\n",
      "[42,500] loss:0.035\n",
      "[42,600] loss:0.031\n",
      "[42,700] loss:0.021\n",
      "[42,800] loss:0.024\n",
      "[42,900] loss:0.031\n",
      "[42,1000] loss:0.019\n",
      "[42,1100] loss:0.067\n",
      "[42,1200] loss:0.028\n",
      "[42,1300] loss:0.024\n",
      "[42,1400] loss:0.056\n",
      "[42,1500] loss:0.029\n",
      "[42,1600] loss:0.068\n",
      "[42,1700] loss:0.053\n",
      "[42,1800] loss:0.042\n",
      "[42,1900] loss:0.031\n",
      "[42,2000] loss:0.060\n",
      "[42,2100] loss:0.034\n",
      "[42,2200] loss:0.036\n",
      "[42,2300] loss:0.016\n",
      "[42,2400] loss:0.024\n",
      "[42,2500] loss:0.017\n",
      "[42,2600] loss:0.032\n",
      "[42,2700] loss:0.018\n",
      "[42,2800] loss:0.050\n",
      "[42,2900] loss:0.047\n",
      "[42,3000] loss:0.032\n",
      "[42,3100] loss:0.027\n",
      "[42,3200] loss:0.041\n",
      "[42,3300] loss:0.036\n",
      "[42,3400] loss:0.062\n",
      "[42,3500] loss:0.031\n",
      "[42,3600] loss:0.025\n",
      "[42,3700] loss:0.021\n",
      "[43,100] loss:0.018\n",
      "[43,200] loss:0.055\n",
      "[43,300] loss:0.025\n",
      "[43,400] loss:0.016\n",
      "[43,500] loss:0.022\n",
      "[43,600] loss:0.067\n",
      "[43,700] loss:0.081\n",
      "[43,800] loss:0.024\n",
      "[43,900] loss:0.031\n",
      "[43,1000] loss:0.014\n",
      "[43,1100] loss:0.029\n",
      "[43,1200] loss:0.046\n",
      "[43,1300] loss:0.037\n",
      "[43,1400] loss:0.050\n",
      "[43,1500] loss:0.043\n",
      "[43,1600] loss:0.039\n",
      "[43,1700] loss:0.023\n",
      "[43,1800] loss:0.045\n",
      "[43,1900] loss:0.039\n",
      "[43,2000] loss:0.053\n",
      "[43,2100] loss:0.048\n",
      "[43,2200] loss:0.018\n",
      "[43,2300] loss:0.051\n",
      "[43,2400] loss:0.031\n",
      "[43,2500] loss:0.060\n",
      "[43,2600] loss:0.034\n",
      "[43,2700] loss:0.052\n",
      "[43,2800] loss:0.038\n",
      "[43,2900] loss:0.040\n",
      "[43,3000] loss:0.049\n",
      "[43,3100] loss:0.054\n",
      "[43,3200] loss:0.046\n",
      "[43,3300] loss:0.026\n",
      "[43,3400] loss:0.027\n",
      "[43,3500] loss:0.031\n",
      "[43,3600] loss:0.029\n",
      "[43,3700] loss:0.042\n",
      "[44,100] loss:0.014\n",
      "[44,200] loss:0.037\n",
      "[44,300] loss:0.018\n",
      "[44,400] loss:0.050\n",
      "[44,500] loss:0.018\n",
      "[44,600] loss:0.039\n",
      "[44,700] loss:0.069\n",
      "[44,800] loss:0.031\n",
      "[44,900] loss:0.029\n",
      "[44,1000] loss:0.040\n",
      "[44,1100] loss:0.040\n",
      "[44,1200] loss:0.032\n",
      "[44,1300] loss:0.038\n",
      "[44,1400] loss:0.027\n",
      "[44,1500] loss:0.035\n",
      "[44,1600] loss:0.029\n",
      "[44,1700] loss:0.040\n",
      "[44,1800] loss:0.016\n",
      "[44,1900] loss:0.053\n",
      "[44,2000] loss:0.027\n",
      "[44,2100] loss:0.071\n",
      "[44,2200] loss:0.041\n",
      "[44,2300] loss:0.034\n",
      "[44,2400] loss:0.042\n",
      "[44,2500] loss:0.047\n",
      "[44,2600] loss:0.047\n",
      "[44,2700] loss:0.044\n",
      "[44,2800] loss:0.025\n",
      "[44,2900] loss:0.033\n",
      "[44,3000] loss:0.052\n",
      "[44,3100] loss:0.016\n",
      "[44,3200] loss:0.021\n",
      "[44,3300] loss:0.030\n",
      "[44,3400] loss:0.021\n",
      "[44,3500] loss:0.037\n",
      "[44,3600] loss:0.054\n",
      "[44,3700] loss:0.078\n",
      "[45,100] loss:0.058\n",
      "[45,200] loss:0.031\n",
      "[45,300] loss:0.038\n",
      "[45,400] loss:0.035\n",
      "[45,500] loss:0.029\n",
      "[45,600] loss:0.018\n",
      "[45,700] loss:0.034\n",
      "[45,800] loss:0.036\n",
      "[45,900] loss:0.052\n",
      "[45,1000] loss:0.030\n",
      "[45,1100] loss:0.032\n",
      "[45,1200] loss:0.032\n",
      "[45,1300] loss:0.031\n",
      "[45,1400] loss:0.036\n",
      "[45,1500] loss:0.068\n",
      "[45,1600] loss:0.041\n",
      "[45,1700] loss:0.050\n",
      "[45,1800] loss:0.033\n",
      "[45,1900] loss:0.061\n",
      "[45,2000] loss:0.052\n",
      "[45,2100] loss:0.023\n",
      "[45,2200] loss:0.051\n",
      "[45,2300] loss:0.036\n",
      "[45,2400] loss:0.042\n",
      "[45,2500] loss:0.021\n",
      "[45,2600] loss:0.040\n",
      "[45,2700] loss:0.012\n",
      "[45,2800] loss:0.033\n",
      "[45,2900] loss:0.036\n",
      "[45,3000] loss:0.013\n",
      "[45,3100] loss:0.016\n",
      "[45,3200] loss:0.080\n",
      "[45,3300] loss:0.022\n",
      "[45,3400] loss:0.039\n",
      "[45,3500] loss:0.050\n",
      "[45,3600] loss:0.034\n",
      "[45,3700] loss:0.035\n",
      "[46,100] loss:0.043\n",
      "[46,200] loss:0.048\n",
      "[46,300] loss:0.033\n",
      "[46,400] loss:0.030\n",
      "[46,500] loss:0.042\n",
      "[46,600] loss:0.062\n",
      "[46,700] loss:0.035\n",
      "[46,800] loss:0.030\n",
      "[46,900] loss:0.027\n",
      "[46,1000] loss:0.037\n",
      "[46,1100] loss:0.040\n",
      "[46,1200] loss:0.040\n",
      "[46,1300] loss:0.038\n",
      "[46,1400] loss:0.043\n",
      "[46,1500] loss:0.041\n",
      "[46,1600] loss:0.027\n",
      "[46,1700] loss:0.023\n",
      "[46,1800] loss:0.028\n",
      "[46,1900] loss:0.029\n",
      "[46,2000] loss:0.029\n",
      "[46,2100] loss:0.032\n",
      "[46,2200] loss:0.026\n",
      "[46,2300] loss:0.051\n",
      "[46,2400] loss:0.054\n",
      "[46,2500] loss:0.025\n",
      "[46,2600] loss:0.028\n",
      "[46,2700] loss:0.050\n",
      "[46,2800] loss:0.031\n",
      "[46,2900] loss:0.055\n",
      "[46,3000] loss:0.037\n",
      "[46,3100] loss:0.030\n",
      "[46,3200] loss:0.033\n",
      "[46,3300] loss:0.036\n",
      "[46,3400] loss:0.031\n",
      "[46,3500] loss:0.029\n",
      "[46,3600] loss:0.025\n",
      "[46,3700] loss:0.033\n",
      "[47,100] loss:0.049\n",
      "[47,200] loss:0.021\n",
      "[47,300] loss:0.044\n",
      "[47,400] loss:0.035\n",
      "[47,500] loss:0.023\n",
      "[47,600] loss:0.047\n",
      "[47,700] loss:0.026\n",
      "[47,800] loss:0.043\n",
      "[47,900] loss:0.036\n",
      "[47,1000] loss:0.037\n",
      "[47,1100] loss:0.041\n",
      "[47,1200] loss:0.036\n",
      "[47,1300] loss:0.026\n",
      "[47,1400] loss:0.029\n",
      "[47,1500] loss:0.054\n",
      "[47,1600] loss:0.040\n",
      "[47,1700] loss:0.038\n",
      "[47,1800] loss:0.019\n",
      "[47,1900] loss:0.061\n",
      "[47,2000] loss:0.028\n",
      "[47,2100] loss:0.021\n",
      "[47,2200] loss:0.043\n",
      "[47,2300] loss:0.046\n",
      "[47,2400] loss:0.029\n",
      "[47,2500] loss:0.059\n",
      "[47,2600] loss:0.043\n",
      "[47,2700] loss:0.030\n",
      "[47,2800] loss:0.022\n",
      "[47,2900] loss:0.040\n",
      "[47,3000] loss:0.037\n",
      "[47,3100] loss:0.058\n",
      "[47,3200] loss:0.028\n",
      "[47,3300] loss:0.034\n",
      "[47,3400] loss:0.059\n",
      "[47,3500] loss:0.033\n",
      "[47,3600] loss:0.018\n",
      "[47,3700] loss:0.035\n",
      "[48,100] loss:0.027\n",
      "[48,200] loss:0.014\n",
      "[48,300] loss:0.031\n",
      "[48,400] loss:0.033\n",
      "[48,500] loss:0.059\n",
      "[48,600] loss:0.031\n",
      "[48,700] loss:0.033\n",
      "[48,800] loss:0.051\n",
      "[48,900] loss:0.062\n",
      "[48,1000] loss:0.027\n",
      "[48,1100] loss:0.021\n",
      "[48,1200] loss:0.039\n",
      "[48,1300] loss:0.032\n",
      "[48,1400] loss:0.057\n",
      "[48,1500] loss:0.039\n",
      "[48,1600] loss:0.064\n",
      "[48,1700] loss:0.020\n",
      "[48,1800] loss:0.058\n",
      "[48,1900] loss:0.050\n",
      "[48,2000] loss:0.032\n",
      "[48,2100] loss:0.025\n",
      "[48,2200] loss:0.019\n",
      "[48,2300] loss:0.021\n",
      "[48,2400] loss:0.017\n",
      "[48,2500] loss:0.038\n",
      "[48,2600] loss:0.061\n",
      "[48,2700] loss:0.031\n",
      "[48,2800] loss:0.042\n",
      "[48,2900] loss:0.048\n",
      "[48,3000] loss:0.023\n",
      "[48,3100] loss:0.043\n",
      "[48,3200] loss:0.038\n",
      "[48,3300] loss:0.038\n",
      "[48,3400] loss:0.037\n",
      "[48,3500] loss:0.044\n",
      "[48,3600] loss:0.027\n",
      "[48,3700] loss:0.037\n",
      "[49,100] loss:0.036\n",
      "[49,200] loss:0.025\n",
      "[49,300] loss:0.030\n",
      "[49,400] loss:0.026\n",
      "[49,500] loss:0.019\n",
      "[49,600] loss:0.055\n",
      "[49,700] loss:0.010\n",
      "[49,800] loss:0.054\n",
      "[49,900] loss:0.055\n",
      "[49,1000] loss:0.032\n",
      "[49,1100] loss:0.043\n",
      "[49,1200] loss:0.058\n",
      "[49,1300] loss:0.027\n",
      "[49,1400] loss:0.033\n",
      "[49,1500] loss:0.026\n",
      "[49,1600] loss:0.016\n",
      "[49,1700] loss:0.016\n",
      "[49,1800] loss:0.053\n",
      "[49,1900] loss:0.023\n",
      "[49,2000] loss:0.044\n",
      "[49,2100] loss:0.066\n",
      "[49,2200] loss:0.048\n",
      "[49,2300] loss:0.032\n",
      "[49,2400] loss:0.053\n",
      "[49,2500] loss:0.050\n",
      "[49,2600] loss:0.031\n",
      "[49,2700] loss:0.024\n",
      "[49,2800] loss:0.038\n",
      "[49,2900] loss:0.039\n",
      "[49,3000] loss:0.034\n",
      "[49,3100] loss:0.016\n",
      "[49,3200] loss:0.038\n",
      "[49,3300] loss:0.072\n",
      "[49,3400] loss:0.029\n",
      "[49,3500] loss:0.045\n",
      "[49,3600] loss:0.044\n",
      "[49,3700] loss:0.049\n",
      "[50,100] loss:0.033\n",
      "[50,200] loss:0.021\n",
      "[50,300] loss:0.021\n",
      "[50,400] loss:0.024\n",
      "[50,500] loss:0.040\n",
      "[50,600] loss:0.019\n",
      "[50,700] loss:0.029\n",
      "[50,800] loss:0.035\n",
      "[50,900] loss:0.028\n",
      "[50,1000] loss:0.037\n",
      "[50,1100] loss:0.024\n",
      "[50,1200] loss:0.026\n",
      "[50,1300] loss:0.027\n",
      "[50,1400] loss:0.024\n",
      "[50,1500] loss:0.015\n",
      "[50,1600] loss:0.022\n",
      "[50,1700] loss:0.032\n",
      "[50,1800] loss:0.038\n",
      "[50,1900] loss:0.069\n",
      "[50,2000] loss:0.033\n",
      "[50,2100] loss:0.025\n",
      "[50,2200] loss:0.042\n",
      "[50,2300] loss:0.040\n",
      "[50,2400] loss:0.036\n",
      "[50,2500] loss:0.060\n",
      "[50,2600] loss:0.026\n",
      "[50,2700] loss:0.060\n",
      "[50,2800] loss:0.027\n",
      "[50,2900] loss:0.063\n",
      "[50,3000] loss:0.024\n",
      "[50,3100] loss:0.034\n",
      "[50,3200] loss:0.026\n",
      "[50,3300] loss:0.019\n",
      "[50,3400] loss:0.020\n",
      "[50,3500] loss:0.056\n",
      "[50,3600] loss:0.033\n",
      "[50,3700] loss:0.022\n",
      "Test Accuracy: 98.55%\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    img_dimension = 28  #dimension of the input images\n",
    "    num_input_channels = 1  #number of input channels (grayscale images)\n",
    "    num_output_classes = 10  #number of output classes (digits 0-9)\n",
    "    batch_size = 16  #number of samples per batch\n",
    "    num_epochs = 50  #number of training epochs\n",
    "    learning_rate = 0.001  #learning rate for the optimizer\n",
    "\n",
    "    #load the training and testing data with transformations\n",
    "    train_dataloader = load_MNIST_data(train_bool=True, transform_img=transform_img(img_dimension), batch_size=batch_size)\n",
    "    test_dataloader = load_MNIST_data(train_bool=False, transform_img=transform_img(img_dimension), batch_size=batch_size)\n",
    "\n",
    "    #train the CNN model\n",
    "    model = train_cnn(num_input_channels=num_input_channels, num_output_classes=num_output_classes, training_dataloader=train_dataloader, num_epochs=num_epochs, learning_rate=learning_rate)\n",
    "\n",
    "    #test the CNN model\n",
    "    accuracy = test_cnn(model, test_dataloader)\n",
    "\n",
    "    #print the test accuracy\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    #save the trained model to a file\n",
    "    torch.save(model.state_dict(), 'CNN_model.pth')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6968\\2171397254.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('CNN_model.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the model class\n",
    "model = CONV_IMG(num_input_channels=1, num_output_classes=10)  \n",
    "\n",
    "# Load the saved model weights\n",
    "model.load_state_dict(torch.load('CNN_model.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
